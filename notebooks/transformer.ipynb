{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f25a0e-eac2-4847-b5e6-f5f6b71b0dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing pytorch\n",
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a163db8-7087-4ff7-a4d9-fa2a73a1a04d",
   "metadata": {},
   "source": [
    "<img src=\"transformer_architecture.png\" width=380 >\n",
    "\n",
    "=> For seq to seq operations we had Extended Neural GPU, ByteNet and Conv S2S \n",
    "=> In these models, no of operations required to related distant datapoints grew with that distance\n",
    "=> No. of operations to relate signals from two arbitrary postitions grow **Linearly** for ConvS2S and **Logarithmically** for ByteNet\n",
    "=> This limits how far we can connect to a sentence. Makes it difficult to learn dependencies between distant positions \n",
    "\n",
    "### Transformer fixes it \n",
    "=> In transformer architecture, this computation to relate distant datapoints reduce. Now to relate distant inputs/outputs we need a **constant amount of operations**.\n",
    "=> But there was a problem, transformer has an issue of **reduced effective resolution**. Which means that model averages attention and context in attention equation. Solution was to introduce Multi-Head attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0e5878-2830-4cf6-90dd-574439efef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class EncoderDecoder(nn.Module) :\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator) : \n",
    "        self.encoder = encoder \n",
    "        self.decoder = decoder \n",
    "        self.src_embed = src_embed \n",
    "        self.tgt_embed = tgt_embed \n",
    "        self.generator = generator \n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask) \n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask) : \n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "            # take in and process masked src and target sequence \n",
    "            return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50473d2c-dea0-4f15-ae87-896cff5df52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# TINKERING WITH ENCODER BLOCKS \n",
    "##########################################################\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "# setting manual seed \n",
    "torch.manual_seed(70404)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# hyper parameters for experimenting \n",
    "VOCAB_SIZE:int = 5 # no of unique tokens we have\n",
    "D_MODEL:int = 2 # dim of vectors we want to convert our tokens into\n",
    "\n",
    "class EncoderBlock(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        # lookup table (converting integers ----> vectors) \n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, D_MODEL)\n",
    "\n",
    "        # the brain that simply learns patterns for now \n",
    "        self.nnl1 = nn.Linear(D_MODEL, D_MODEL)\n",
    "\n",
    "    def forward(self, x, debug:bool=True): \n",
    "        # x is a batch of sentences represented as integers \n",
    "        # we want to convert them into vectors and then learn patterns from them\n",
    "\n",
    "        # when we need debug flag, we will send debug=True and get printed logs to understand data better hehe ;)\n",
    "        self.debug = debug \n",
    "        if self.debug:\n",
    "            print(\"\\n--- [ENCODER START] ---\")\n",
    "            print(f\"1. Raw Input (Token IDs):\\n   {x}\")\n",
    "            print(f\"   Shape: {x.shape}\")\n",
    "\n",
    "        # STEP 1: EMBEDDING\n",
    "        # We look up the vector for each integer.\n",
    "        x = self.embedding(x)\n",
    "        if self.debug:\n",
    "            print(f\"\\n2. After Embedding (Integers -> Vectors):\")\n",
    "            print(f\"Vector after embedding: {x.tolist()}\") \n",
    "            print(f\"Shape: {x.shape}\")\n",
    "\n",
    "        # STEP 2: PROCESSING (The Neural Network)\n",
    "        # The model multiplies the embedding by weights to \"understand\" it.\n",
    "        x = self.nnl1(x) # passing through the linear layer 1\n",
    "        if self.debug:\n",
    "            print(f\"\\n3. After Linear Layer (The 'Thinking' Step):\")\n",
    "            print(f\"First token transformed to: {x[0][0].tolist()}\")\n",
    "            print(f\"Output of Linear layer: {x.tolist()}\")\n",
    "            print(f\"   Shape: {x.shape}\")\n",
    "\n",
    "        return x # returning the processed vectors to get the output pos\n",
    "    \n",
    "\n",
    "encoder : EncoderBlock = EncoderBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231e336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [ENCODER START] ---\n",
      "1. Raw Input (Token IDs):\n",
      "   tensor([[1, 2, 3]])\n",
      "   Shape: torch.Size([1, 3])\n",
      "\n",
      "2. After Embedding (Integers -> Vectors):\n",
      "Vector after embedding: [[[-0.05909673497080803, 0.353969544172287], [0.2251233160495758, -0.27265700697898865], [-1.3874330520629883, 1.1006890535354614]]]\n",
      "Shape: torch.Size([1, 3, 2])\n",
      "\n",
      "3. After Linear Layer (The 'Thinking' Step):\n",
      "First token transformed to: [-0.31872737407684326, 0.33177289366722107]\n",
      "Output of Linear layer: [[[-0.31872737407684326, 0.33177289366722107], [-0.6656067371368408, 0.36282414197921753], [0.03372323513031006, 0.7046524882316589]]]\n",
      "   Shape: torch.Size([1, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3187,  0.3318],\n",
       "         [-0.6656,  0.3628],\n",
       "         [ 0.0337,  0.7047]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en_tokens \n",
    "en_tokens = torch.tensor([[1,2,3]]) # batch of 1 sentences\n",
    "\n",
    "# running the encoder \n",
    " # we don't need gradients for this test\n",
    "encoder_output = encoder(en_tokens)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3207f5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2030,  1.0051],\n",
       "        [-0.0591,  0.3540],\n",
       "        [ 0.2251, -0.2727],\n",
       "        [-1.3874,  1.1007],\n",
       "        [-1.9443, -0.2719]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b81c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0615,  0.5815],\n",
       "        [-0.4142, -0.2374]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.nnl1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f58d85",
   "metadata": {},
   "source": [
    "##### Problems with this approach\n",
    "Let us say, [1,2,3] is ['I', 'am', 'dog'].<br>\n",
    "Here after embedding with d_model=3, we get [[0.1, 02], [0.3, 0.4], [0.5, 0.6]] (just an example).<br>\n",
    "Now, the embedding vector for 'dog'(3) is [0.5, 0.6]<br>\n",
    "1. The embedding vector for 'dog' = [0.5, 0.6] --> [0.9, 0.6] (after passing through linear layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c74df238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dummy input in memory: 12 bytes\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.tensor([[1,2,3]], dtype=torch.float32) \n",
    "\n",
    "print(f\"Size of dummy input in memory: {dummy_input.element_size() * dummy_input.nelement()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4cc008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Output for: [[1, 2, 3]]\n",
      "[-0.05909673497080803, 0.353969544172287]\n",
      "[0.2251233160495758, -0.27265700697898865]\n",
      "[-1.3874330520629883, 1.1006890535354614]\n",
      "\n",
      "Passing this embedded matrix into the linear layer...\n",
      "[-0.31872737407684326, 0.33177289366722107]\n",
      "[-0.6656067371368408, 0.36282414197921753]\n",
      "[0.03372323513031006, 0.7046524882316589]\n",
      "\n",
      "Neural net Weights:\n",
      "[0.061545372009277344, 0.5814815163612366]\n",
      "[-0.4141703248023987, -0.23740896582603455]\n",
      "\n",
      "Embedding Lookup Table:\n",
      "[0.20301564037799835, 1.005134105682373]\n",
      "[-0.05909673497080803, 0.353969544172287]\n",
      "[0.2251233160495758, -0.27265700697898865]\n",
      "[-1.3874330520629883, 1.1006890535354614]\n",
      "[-1.944254755973816, -0.27188217639923096]\n"
     ]
    }
   ],
   "source": [
    "# tunnel problem \n",
    "# let us say [1,2,3] = ['I', 'am', 'dog']\n",
    "embed_output = encoder.embedding(dummy_input.long())\n",
    "print(f\"Embedding Output for: {en_tokens.tolist()}\")\n",
    "for i in embed_output[0]: print(i.tolist())\n",
    "print(\"\\nPassing this embedded matrix into the linear layer...\")\n",
    "ll1_output = encoder.nnl1(embed_output)\n",
    "for i in ll1_output[0]: print(i.tolist())\n",
    "\n",
    "print(\"\\nNeural net Weights:\")\n",
    "for i in encoder.nnl1.weight: print(i.tolist())\n",
    "\n",
    "print(\"\\nEmbedding Lookup Table:\")\n",
    "for i in encoder.embedding.weight: print(i.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1c4a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Output for: [[3.0, 2.0, 1.0]]\n",
      "[-1.3874330520629883, 1.1006890535354614]\n",
      "[0.2251233160495758, -0.27265700697898865]\n",
      "[-0.05909673497080803, 0.353969544172287]\n",
      "\n",
      "Passing this embedded matrix into the linear layer...\n",
      "[0.03372323513031006, 0.7046524882316589]\n",
      "[-0.6656067371368408, 0.36282414197921753]\n",
      "[-0.31872737407684326, 0.33177289366722107]\n",
      "\n",
      "Neural net Weights:\n",
      "[0.061545372009277344, 0.5814815163612366]\n",
      "[-0.4141703248023987, -0.23740896582603455]\n",
      "\n",
      "Embedding Lookup Table:\n",
      "[0.20301564037799835, 1.005134105682373]\n",
      "[-0.05909673497080803, 0.353969544172287]\n",
      "[0.2251233160495758, -0.27265700697898865]\n",
      "[-1.3874330520629883, 1.1006890535354614]\n",
      "[-1.944254755973816, -0.27188217639923096]\n"
     ]
    }
   ],
   "source": [
    "dummy_input_reverse = torch.tensor([[3,2,1]], dtype=torch.float32)\n",
    "embed_output = encoder.embedding(dummy_input_reverse.long())\n",
    "print(f\"Embedding Output for: {dummy_input_reverse.tolist()}\")\n",
    "for i in embed_output[0]: print(i.tolist())\n",
    "print(\"\\nPassing this embedded matrix into the linear layer...\")\n",
    "ll1_output = encoder.nnl1(embed_output)\n",
    "for i in ll1_output[0]: print(i.tolist())\n",
    "\n",
    "print(\"\\nNeural net Weights:\")\n",
    "for i in encoder.nnl1.weight: print(i.tolist())\n",
    "\n",
    "print(\"\\nEmbedding Lookup Table:\")\n",
    "for i in encoder.embedding.weight: print(i.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704e61b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog representation in 'I am dog': tensor([-0.6656,  0.3628], grad_fn=<SelectBackward0>)\n",
      "Dog representation in 'He is dog': tensor([-0.6656,  0.3628], grad_fn=<SelectBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "iamdog:torch.Tensor = torch.tensor([0,1,2]) # 1='i', 2='am', 3='dog'\n",
    "heisgod:torch.Tensor = torch.tensor([3,4,2]) # 3='he', 2='is', 1='dog'\n",
    "# intuitively, dog in both sentence have different meaning \n",
    "# in sentence 1, dog is a pet\n",
    "# in sentence 2, dog is an insult\n",
    "# we need the sentences to be different in order to learn different patterns for the word 'dog' in both sentences.\n",
    "\n",
    "# but here is it not like that, as seen below \n",
    "print(\"Dog representation in 'I am dog':\", encoder(iamdog, debug=False)[2])\n",
    "print(\"Dog representation in 'He is dog':\", encoder(heisgod, debug=False)[2])\n",
    "\n",
    "print(encoder(iamdog, debug=False)[2].tolist() == encoder(heisgod, debug=False)[2].tolist())\n",
    "#\"The 'dog' token has the same representation in both sentences, which is a problem for learning different meanings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc8f585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[44, 78, 1597, 1927, 5197, 1599, 2317, 1585, 1...</td>\n",
       "      <td>[1788, 1830, 2778, 1563, 2457, 3771, 2016, 258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2345, 2381, 72, 1578, 1546, 2345, 72, 1585, 1...</td>\n",
       "      <td>[4656, 1954, 1530, 1592, 1777, 932, 2457, 3771...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1668, 1751, 5422, 1745, 90, 76, 1551, 1612, 9...</td>\n",
       "      <td>[1571, 5305, 479, 4523, 1520, 1614, 2025, 480,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1668, 1751, 5422, 1745, 90, 76, 1551, 1612, 9...</td>\n",
       "      <td>[447, 479, 1796, 479, 4523, 1520, 1614, 2025, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[934, 4053, 1526, 1745, 90, 76, 3455, 1634, 16...</td>\n",
       "      <td>[2091, 1827, 487, 963, 1066, 444, 1828, 1539, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  [44, 78, 1597, 1927, 5197, 1599, 2317, 1585, 1...   \n",
       "1  [2345, 2381, 72, 1578, 1546, 2345, 72, 1585, 1...   \n",
       "2  [1668, 1751, 5422, 1745, 90, 76, 1551, 1612, 9...   \n",
       "3  [1668, 1751, 5422, 1745, 90, 76, 1551, 1612, 9...   \n",
       "4  [934, 4053, 1526, 1745, 90, 76, 3455, 1634, 16...   \n",
       "\n",
       "                                                  hi  \n",
       "0  [1788, 1830, 2778, 1563, 2457, 3771, 2016, 258...  \n",
       "1  [4656, 1954, 1530, 1592, 1777, 932, 2457, 3771...  \n",
       "2  [1571, 5305, 479, 4523, 1520, 1614, 2025, 480,...  \n",
       "3  [447, 479, 1796, 479, 4523, 1520, 1614, 2025, ...  \n",
       "4  [2091, 1827, 487, 963, 1066, 444, 1828, 1539, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df :pd.DataFrame = pd.read_parquet(\"../datasets/iitb/tokenised/train_tokens.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4694de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659083"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5bac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vector = df.iloc[0]['en'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cd4547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  44,   78, 1597, 1927, 5197, 1599, 2317, 1585, 1615, 4844, 1797,   80,\n",
       "         1863]),\n",
       " tensor([1788, 1830, 2778, 1563, 2457, 3771, 2016, 2583, 2470, 1584,  975, 1558,\n",
       "         3570, 3903]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make the dataloader \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Any\n",
    "\n",
    "# creating a custom dataset class \n",
    "class IITBDataset(Dataset):\n",
    "    \"\"\"Custom dataset for IITB English-Hindi translation data.\"\"\"\n",
    "    def __init__(self, dataframe:pd.DataFrame) -> None :\n",
    "        self.df = dataframe \n",
    "\n",
    "    def __len__(self) -> int: \n",
    "        return int(len(self.df))\n",
    "\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        \"\"\"returns en_vector, hi_vector for the given index\"\"\"\n",
    "        if index >= len(self.df): raise IndexError(\"Index out of range\")\n",
    "        en_vector:list[int] = self.df.iloc[index]['en'].tolist()\n",
    "        hi_vector:list[int] = self.df.iloc[index]['hi'].tolist()\n",
    "        return torch.tensor(en_vector, dtype=torch.long), torch.tensor(hi_vector, dtype=torch.long)\n",
    "   \n",
    "dataset = IITBDataset(df)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4ee9920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [44, 78, 1597, 1927, 5197, 1599, 2317, 1585, 1...\n",
       "1          [2345, 2381, 72, 1578, 1546, 2345, 72, 1585, 1...\n",
       "2          [1668, 1751, 5422, 1745, 90, 76, 1551, 1612, 9...\n",
       "3          [1668, 1751, 5422, 1745, 90, 76, 1551, 1612, 9...\n",
       "4          [934, 4053, 1526, 1745, 90, 76, 3455, 1634, 16...\n",
       "                                 ...                        \n",
       "1659078    [1668, 5148, 3898, 1088, 3569, 51, 1529, 2092,...\n",
       "1659079    [2145, 925, 89, 2100, 1826, 1088, 1519, 5148, ...\n",
       "1659080    [981, 2119, 1675, 2251, 1556, 1754, 1738, 1707...\n",
       "1659081    [1668, 51, 41, 934, 4282, 1759, 2525, 4299, 16...\n",
       "1659082    [981, 2208, 1845, 1707, 4701, 4430, 1743, 1519...\n",
       "Name: en, Length: 1659083, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking vector lengths of our tokenised data \n",
    "df['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3d9048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   en  hi\n",
       "0  13  14\n",
       "1  15  14\n",
       "2  18  17\n",
       "3  15  18\n",
       "4  15  22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "len_df = copy.deepcopy(df) \n",
    "len_df['en'] = len_df['en'].apply(len) \n",
    "len_df['hi'] = len_df['hi'].apply(len)\n",
    "len_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a9abb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.659083e+06</td>\n",
       "      <td>1.659083e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.358597e+01</td>\n",
       "      <td>2.429923e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.644010e+01</td>\n",
       "      <td>2.705710e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>3.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.573000e+03</td>\n",
       "      <td>4.014000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 en            hi\n",
       "count  1.659083e+06  1.659083e+06\n",
       "mean   2.358597e+01  2.429923e+01\n",
       "std    2.644010e+01  2.705710e+01\n",
       "min    0.000000e+00  0.000000e+00\n",
       "25%    6.000000e+00  6.000000e+00\n",
       "50%    1.600000e+01  1.600000e+01\n",
       "75%    3.200000e+01  3.300000e+01\n",
       "max    4.573000e+03  4.014000e+03"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b228adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- English Stats ---\n",
      "95th Percentile: 69.0\n",
      "99th Percentile: 117.0\n",
      "\n",
      "--- Hindi Stats ---\n",
      "95th Percentile: 72.0\n",
      "99th Percentile: 124.0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- English Stats ---\")\n",
    "print(f\"95th Percentile: {len_df['en'].quantile(0.95)}\")\n",
    "print(f\"99th Percentile: {len_df['en'].quantile(0.99)}\")\n",
    "print(\"\\n--- Hindi Stats ---\")\n",
    "print(f\"95th Percentile: {len_df['hi'].quantile(0.95)}\")\n",
    "print(f\"99th Percentile: {len_df['hi'].quantile(0.99)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e49e2bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded output: I am dog\n",
      "length of tokenised vector: 125\n"
     ]
    }
   ],
   "source": [
    "import tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers import decoders\n",
    "\n",
    "pad_index:int = 1\n",
    "max_seq_length:int = 125\n",
    "\n",
    "tokeniser : Tokenizer = Tokenizer.from_file(\"../datasets/iitb/tokeniser/bpe_tokeniser_32k.json\")\n",
    "tokeniser.decoder = decoders.BPEDecoder(suffix=\"</w>\")\n",
    "tokeniser.enable_padding(direction='right',pad_id=1, pad_token='[PAD]',length=max_seq_length)\n",
    "tokeniser.enable_truncation(max_length=max_seq_length)\n",
    "\n",
    "iamdog: tokenizers.Encoding = tokeniser.encode(\"[SOS] I am dog [EOS]\")\n",
    "iamdog_tokens, iamdog_ids = iamdog.tokens, iamdog.ids\n",
    "\n",
    "\n",
    "print(f'decoded output: {tokeniser.decode(iamdog_ids)}')\n",
    "print(f'length of tokenised vector: {len(iamdog_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dbb5592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SOS] Give your application an accessibility w...</td>\n",
       "      <td>[SOS] अपने अनुप्रयोग को पहुंचनीयता व्यायाम का ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[SOS] Accerciser Accessibility Explorer [EOS]</td>\n",
       "      <td>[SOS] एक्सेर्साइसर पहुंचनीयता अन्वेषक [EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[SOS] The default plugin layout for the bottom...</td>\n",
       "      <td>[SOS] निचले पटल के लिए डिफोल्ट प्लग-इन खाका [EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SOS] The default plugin layout for the top pa...</td>\n",
       "      <td>[SOS] ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका [EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[SOS] A list of plugins that are disabled by d...</td>\n",
       "      <td>[SOS] उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  [SOS] Give your application an accessibility w...   \n",
       "1      [SOS] Accerciser Accessibility Explorer [EOS]   \n",
       "2  [SOS] The default plugin layout for the bottom...   \n",
       "3  [SOS] The default plugin layout for the top pa...   \n",
       "4  [SOS] A list of plugins that are disabled by d...   \n",
       "\n",
       "                                                  hi  \n",
       "0  [SOS] अपने अनुप्रयोग को पहुंचनीयता व्यायाम का ...  \n",
       "1        [SOS] एक्सेर्साइसर पहुंचनीयता अन्वेषक [EOS]  \n",
       "2  [SOS] निचले पटल के लिए डिफोल्ट प्लग-इन खाका [EOS]  \n",
       "3   [SOS] ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका [EOS]  \n",
       "4  [SOS] उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../datasets/iitb/raw/train.parquet\", engine=\"pyarrow\").map(lambda x: str(\"[SOS] \" + str(x) + \" [EOS]\")) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bedd666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[SOS] Give your application an accessibility workout [EOS]',\n",
       " '[SOS] अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें [EOS]')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['en'][0],df['hi'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50e038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "english-hindi-translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
